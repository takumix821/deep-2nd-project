{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5401a171",
   "metadata": {},
   "source": [
    "### Confirm Tensorflow Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304bcb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3c573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "#tf.test.is_built_with_cuda()\n",
    "#tf.test.is_built_with_gpu_support()\n",
    "#tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9702e06",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c932c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02686e89",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0278dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 25000 files.\n",
      "folder: ['0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "#Data visiting â€“ os.walk()\n",
    "\n",
    "label_folder = []\n",
    "total_size = 0\n",
    "data_path = r\"D:\\CIFAR10_Test Image\\Training_data\"\n",
    "\n",
    "#os.walk() generates the file names(dirpath, dirnames, filenames) \n",
    "#in a directory tree by walking the tree either top-down or bottom-up.\n",
    "for root, dirts, files in os.walk(data_path): \n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    total_size += len(files)\n",
    "\n",
    "    \n",
    "print(\"found\",total_size,\"files.\")\n",
    "print(\"folder:\",label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecec1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "#Load image\n",
    "\n",
    "base_x_train = []\n",
    "base_y_train = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        \n",
    "        base_x_train.append(img)\n",
    "        base_y_train.append(label_folder[i])\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4524f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 32, 32, 3)\n",
      "(25000, 5)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Convert a category vector to a binary (0 or 1) matrix-type representation\n",
    "\n",
    "base_y_train = to_categorical(base_y_train)\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef7560",
   "metadata": {},
   "source": [
    "### Splitting the Data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b2f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (20000, 32, 32, 3) (20000, 5)\n",
      "Validation data: (5000, 32, 32, 3) (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split( \\\n",
    "    np.array(base_x_train), np.array(base_y_train), test_size=0.2, random_state = 0)\n",
    "\n",
    "print(\"Training data:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation data:\", x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fcdd8",
   "metadata": {},
   "source": [
    "### Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cee274df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 2\n",
      "Answer(one-hot): [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = random.randint(0, x_train.shape[0])\n",
    "plt.imshow(x_train[idx])\n",
    "plt.show()\n",
    "\n",
    "print(\"Answer:\", np.argmax(y_train[idx]))\n",
    "print(\"Answer(one-hot):\", y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03800027",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47cd5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77060e81",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59632ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 59s 118ms/step - loss: 1.4054 - accuracy: 0.4288 - val_loss: 1.2394 - val_accuracy: 0.5368\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 1.1493 - accuracy: 0.5542 - val_loss: 1.1008 - val_accuracy: 0.5556\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 0.9960 - accuracy: 0.6149 - val_loss: 0.9931 - val_accuracy: 0.6160\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 0.8860 - accuracy: 0.6626 - val_loss: 0.8966 - val_accuracy: 0.6566\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 0.8034 - accuracy: 0.6959 - val_loss: 0.8060 - val_accuracy: 0.6954\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 50s 124ms/step - loss: 0.7351 - accuracy: 0.7222 - val_loss: 0.8083 - val_accuracy: 0.6876\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 0.6688 - accuracy: 0.7508 - val_loss: 0.7474 - val_accuracy: 0.7166\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 0.6088 - accuracy: 0.7773 - val_loss: 0.6995 - val_accuracy: 0.7376\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 0.5431 - accuracy: 0.8051 - val_loss: 0.7270 - val_accuracy: 0.7168\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 0.4852 - accuracy: 0.8298 - val_loss: 0.6368 - val_accuracy: 0.7626\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47cd5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59632ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 46s 113ms/step - loss: 1.4504 - accuracy: 0.4072 - val_loss: 1.2915 - val_accuracy: 0.4636\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 1.0294 - accuracy: 0.5842 - val_loss: 1.0354 - val_accuracy: 0.5748\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 0.8796 - accuracy: 0.6532 - val_loss: 0.8075 - val_accuracy: 0.6916\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.7645 - accuracy: 0.7039 - val_loss: 0.8339 - val_accuracy: 0.6662\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.6645 - accuracy: 0.7474 - val_loss: 0.7509 - val_accuracy: 0.7104\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.5791 - accuracy: 0.7827 - val_loss: 0.7218 - val_accuracy: 0.7356\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.4992 - accuracy: 0.8142 - val_loss: 0.7554 - val_accuracy: 0.7328\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 0.4241 - accuracy: 0.8418 - val_loss: 0.6401 - val_accuracy: 0.7718\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.3529 - accuracy: 0.8690 - val_loss: 0.6644 - val_accuracy: 0.7712\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 0.2809 - accuracy: 0.8988 - val_loss: 0.7219 - val_accuracy: 0.7622\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model2.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model2.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47cd5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='softmax'),\n",
    "    tf.keras.layers.Dense(128, activation='softmax'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59632ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 48s 116ms/step - loss: 1.6095 - accuracy: 0.1988 - val_loss: 1.6095 - val_accuracy: 0.1934\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 1.6094 - accuracy: 0.2012 - val_loss: 1.6094 - val_accuracy: 0.1934\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 1.6093 - accuracy: 0.2012 - val_loss: 1.6094 - val_accuracy: 0.1934\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 1.6093 - accuracy: 0.2018 - val_loss: 1.6094 - val_accuracy: 0.2020\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 1.6093 - accuracy: 0.2024 - val_loss: 1.6094 - val_accuracy: 0.1940\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 1.6093 - accuracy: 0.2030 - val_loss: 1.6093 - val_accuracy: 0.2286\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 1.6093 - accuracy: 0.2127 - val_loss: 1.6094 - val_accuracy: 0.1934\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 46s 116ms/step - loss: 1.6092 - accuracy: 0.2028 - val_loss: 1.6093 - val_accuracy: 0.1934\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 1.6092 - accuracy: 0.2022 - val_loss: 1.6093 - val_accuracy: 0.1934\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 1.6092 - accuracy: 0.2022 - val_loss: 1.6092 - val_accuracy: 0.1934\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model3.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model3.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cd5da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(128, activation='tanh'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59632ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 46s 113ms/step - loss: 1.6189 - accuracy: 0.2010 - val_loss: 1.6294 - val_accuracy: 0.2040\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 45s 113ms/step - loss: 1.6161 - accuracy: 0.1996 - val_loss: 1.6151 - val_accuracy: 0.1962\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 45s 112ms/step - loss: 1.6167 - accuracy: 0.1963 - val_loss: 1.6139 - val_accuracy: 0.2044\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 45s 112ms/step - loss: 1.6147 - accuracy: 0.2036 - val_loss: 1.6127 - val_accuracy: 0.1962\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 45s 112ms/step - loss: 1.6155 - accuracy: 0.2029 - val_loss: 1.6148 - val_accuracy: 0.2036\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 45s 111ms/step - loss: 1.6153 - accuracy: 0.2056 - val_loss: 1.6209 - val_accuracy: 0.2038\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 44s 111ms/step - loss: 1.6152 - accuracy: 0.2018 - val_loss: 1.6140 - val_accuracy: 0.2028\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 44s 111ms/step - loss: 1.6159 - accuracy: 0.2060 - val_loss: 1.6140 - val_accuracy: 0.2040\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 45s 111ms/step - loss: 1.6146 - accuracy: 0.2051 - val_loss: 1.6119 - val_accuracy: 0.1962\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 45s 112ms/step - loss: 1.6161 - accuracy: 0.1957 - val_loss: 1.6146 - val_accuracy: 0.1936\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model4.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model4.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa37c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a440e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 44s 110ms/step - loss: 1.4192 - accuracy: 0.4236 - val_loss: 1.2249 - val_accuracy: 0.5536\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 1.1578 - accuracy: 0.5572 - val_loss: 1.0715 - val_accuracy: 0.5706\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 1.0013 - accuracy: 0.6172 - val_loss: 0.9554 - val_accuracy: 0.6386\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 0.8846 - accuracy: 0.6650 - val_loss: 0.8479 - val_accuracy: 0.6824\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 49s 122ms/step - loss: 0.7972 - accuracy: 0.6997 - val_loss: 0.8468 - val_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 0.7177 - accuracy: 0.7333 - val_loss: 0.9565 - val_accuracy: 0.6238\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 46s 114ms/step - loss: 0.6509 - accuracy: 0.7610 - val_loss: 0.6958 - val_accuracy: 0.7414\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 0.5798 - accuracy: 0.7914 - val_loss: 0.6772 - val_accuracy: 0.7476\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 0.5224 - accuracy: 0.8124 - val_loss: 0.6355 - val_accuracy: 0.7648\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 45s 114ms/step - loss: 0.4600 - accuracy: 0.8391 - val_loss: 0.6388 - val_accuracy: 0.7542\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model5.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model5.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b756cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c29b148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 47s 116ms/step - loss: 6.2271 - accuracy: 0.2017 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 46s 116ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 46s 115ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 6.4464 - accuracy: 0.2009 - val_loss: 6.4505 - val_accuracy: 0.1962\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model6.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model6.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e2cf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8c80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 47s 112ms/step - loss: 4.3181 - accuracy: 0.2512 - val_loss: 4.3589 - val_accuracy: 0.2830\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 4.2836 - accuracy: 0.2835 - val_loss: 4.2641 - val_accuracy: 0.3470\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 50s 125ms/step - loss: 2.2633 - accuracy: 0.2282 - val_loss: 1.6444 - val_accuracy: 0.2028\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 1.6172 - accuracy: 0.2046 - val_loss: 1.6083 - val_accuracy: 0.2176\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 50s 126ms/step - loss: 1.6078 - accuracy: 0.2212 - val_loss: 1.6073 - val_accuracy: 0.2200\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 47s 119ms/step - loss: 1.6068 - accuracy: 0.2353 - val_loss: 1.6061 - val_accuracy: 0.2374\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 47s 119ms/step - loss: 1.6053 - accuracy: 0.2451 - val_loss: 1.6042 - val_accuracy: 0.2408\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 47s 118ms/step - loss: 1.6025 - accuracy: 0.2526 - val_loss: 1.6004 - val_accuracy: 0.2800\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 1.5964 - accuracy: 0.2592 - val_loss: 1.5890 - val_accuracy: 0.2658\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 47s 117ms/step - loss: 1.5799 - accuracy: 0.2698 - val_loss: 1.5732 - val_accuracy: 0.2998\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch_size = 50\n",
    "\n",
    "model7.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model7.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5dedd",
   "metadata": {},
   "source": [
    "### Saving the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "073526c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model0501.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6411dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"my_model0501.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef54cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,686,981\n",
      "Trainable params: 1,686,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8438b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model2.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38e211c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 4., ..., 4., 1., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°‡outputæ”¹ç‚ºæ¨™ç±¤\n",
    "output_y = np.zeros(y_hat.shape[0])\n",
    "\n",
    "for i in range(y_hat.shape[0]):\n",
    "    for j in range(y_hat.shape[1]):\n",
    "        if y_hat[i, j] >= max(y_hat[i, ]):\n",
    "            output_y[i] = j\n",
    "\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ccc3cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 4., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_yv = np.zeros(y_valid.shape[0])\n",
    "\n",
    "for i in range(y_valid.shape[0]):\n",
    "    for j in range(y_valid.shape[1]):\n",
    "        if y_valid[i, j] >= max(y_valid[i, ]):\n",
    "            output_yv[i] = j\n",
    "\n",
    "output_yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f1f4fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(output_y == output_yv) / len(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c5a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
