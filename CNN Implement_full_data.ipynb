{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5401a171",
   "metadata": {},
   "source": [
    "### Confirm Tensorflow Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304bcb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9702e06",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9c932c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir \n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02686e89",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e0278dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 50000 files.\n",
      "folder: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "#Data visiting â€“ os.walk()\n",
    "\n",
    "label_folder = []\n",
    "total_size = 0\n",
    "data_path = r\"D:\\cifar10\\train\"\n",
    "\n",
    "#os.walk() generates the file names(dirpath, dirnames, filenames) \n",
    "#in a directory tree by walking the tree either top-down or bottom-up.\n",
    "for root, dirts, files in os.walk(data_path): \n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    total_size += len(files)\n",
    "\n",
    "    \n",
    "print(\"found\",total_size,\"files.\")\n",
    "print(\"folder:\",label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecec1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#Load image\n",
    "\n",
    "base_x_train = []\n",
    "base_y_train = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        \n",
    "        base_x_train.append(img)\n",
    "        base_y_train.append(label_folder[i])\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4524f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#Convert a category vector to a binary (0 or 1) matrix-type representation\n",
    "\n",
    "base_y_train = to_categorical(base_y_train)\n",
    "\n",
    "\n",
    "print(np.array(base_x_train).shape)\n",
    "print(np.array(base_y_train).shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef7560",
   "metadata": {},
   "source": [
    "### Splitting the Data into training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8b2f1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (40000, 32, 32, 3) (40000, 10)\n",
      "Validation data: (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split( \\\n",
    "    np.array(base_x_train), np.array(base_y_train), test_size=0.2, random_state = 0)\n",
    "\n",
    "print(\"Training data:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation data:\", x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fcdd8",
   "metadata": {},
   "source": [
    "### Show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cee274df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 0\n",
      "Answer(one-hot): [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = random.randint(0, x_train.shape[0])\n",
    "plt.imshow(x_train[idx])\n",
    "plt.show()\n",
    "\n",
    "print(\"Answer:\", np.argmax(y_train[idx]))\n",
    "print(\"Answer(one-hot):\", y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03800027",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d57f1",
   "metadata": {},
   "source": [
    "You can show the detail for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d5c1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4, 4), padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f278291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,375,754\n",
      "Trainable params: 2,375,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77060e81",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bd9f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1334/1334 [==============================] - 118s 88ms/step - loss: 1.9979 - accuracy: 0.3019 - val_loss: 1.7998 - val_accuracy: 0.3651\n",
      "Epoch 2/15\n",
      "1334/1334 [==============================] - 123s 93ms/step - loss: 1.5762 - accuracy: 0.4495 - val_loss: 1.4306 - val_accuracy: 0.4982\n",
      "Epoch 3/15\n",
      "1334/1334 [==============================] - 121s 91ms/step - loss: 1.3079 - accuracy: 0.5460 - val_loss: 1.8971 - val_accuracy: 0.3319\n",
      "Epoch 4/15\n",
      "1334/1334 [==============================] - 119s 90ms/step - loss: 1.0947 - accuracy: 0.6209 - val_loss: 1.1407 - val_accuracy: 0.6041\n",
      "Epoch 5/15\n",
      "1334/1334 [==============================] - 117s 88ms/step - loss: 0.9281 - accuracy: 0.6830 - val_loss: 0.9460 - val_accuracy: 0.6734\n",
      "Epoch 6/15\n",
      "1334/1334 [==============================] - 122s 92ms/step - loss: 0.7817 - accuracy: 0.7333 - val_loss: 0.8072 - val_accuracy: 0.7191\n",
      "Epoch 7/15\n",
      "1334/1334 [==============================] - 116s 87ms/step - loss: 0.6521 - accuracy: 0.7794 - val_loss: 0.7969 - val_accuracy: 0.7260\n",
      "Epoch 8/15\n",
      "1334/1334 [==============================] - 118s 88ms/step - loss: 0.5369 - accuracy: 0.8236 - val_loss: 0.9457 - val_accuracy: 0.6692\n",
      "Epoch 9/15\n",
      "1334/1334 [==============================] - 118s 88ms/step - loss: 0.4207 - accuracy: 0.8668 - val_loss: 0.7547 - val_accuracy: 0.7439\n",
      "Epoch 10/15\n",
      "1334/1334 [==============================] - 117s 87ms/step - loss: 0.3068 - accuracy: 0.9094 - val_loss: 0.7167 - val_accuracy: 0.7590\n",
      "Epoch 11/15\n",
      "1334/1334 [==============================] - 114s 86ms/step - loss: 0.1994 - accuracy: 0.9498 - val_loss: 0.6882 - val_accuracy: 0.7711\n",
      "Epoch 12/15\n",
      "1334/1334 [==============================] - 117s 88ms/step - loss: 0.1097 - accuracy: 0.9804 - val_loss: 0.7132 - val_accuracy: 0.7693\n",
      "Epoch 13/15\n",
      "1334/1334 [==============================] - 115s 86ms/step - loss: 0.0530 - accuracy: 0.9958 - val_loss: 0.7031 - val_accuracy: 0.7845\n",
      "Epoch 14/15\n",
      "1334/1334 [==============================] - 116s 87ms/step - loss: 0.0269 - accuracy: 0.9991 - val_loss: 0.6967 - val_accuracy: 0.7909\n",
      "Epoch 15/15\n",
      "1334/1334 [==============================] - 117s 88ms/step - loss: 0.0173 - accuracy: 0.9997 - val_loss: 0.7030 - val_accuracy: 0.7936\n"
     ]
    }
   ],
   "source": [
    "epoch = 15\n",
    "batch_size = 30\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epoch, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5dedd",
   "metadata": {},
   "source": [
    "### Saving the trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "073526c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6411dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model(\"my_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef54cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,375,754\n",
      "Trainable params: 2,375,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8438b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model2.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38e211c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 9., ..., 9., 7., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°‡outputæ”¹ç‚ºæ¨™ç±¤\n",
    "output_y = np.zeros(y_hat.shape[0])\n",
    "\n",
    "for i in range(y_hat.shape[0]):\n",
    "    for j in range(y_hat.shape[1]):\n",
    "        if y_hat[i, j] >= max(y_hat[i, ]):\n",
    "            output_y[i] = j\n",
    "\n",
    "output_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccc3cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 9., ..., 9., 7., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_yv = np.zeros(y_valid.shape[0])\n",
    "\n",
    "for i in range(y_valid.shape[0]):\n",
    "    for j in range(y_valid.shape[1]):\n",
    "        if y_valid[i, j] >= max(y_valid[i, ]):\n",
    "            output_yv[i] = j\n",
    "\n",
    "output_yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f1f4fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(output_y == output_yv) / len(output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a729bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 10000 files.\n",
      "folder: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "label_folder = []\n",
    "total_size = 0\n",
    "data_path = r\"D:\\cifar10\\test\"\n",
    "\n",
    "#os.walk() generates the file names(dirpath, dirnames, filenames) \n",
    "#in a directory tree by walking the tree either top-down or bottom-up.\n",
    "for root, dirts, files in os.walk(data_path): \n",
    "    for dirt in dirts:\n",
    "        label_folder.append(dirt)\n",
    "    total_size += len(files)\n",
    "\n",
    "    \n",
    "print(\"found\",total_size,\"files.\")\n",
    "print(\"folder:\",label_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "931c4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "base_x_test = []\n",
    "base_y_test = []\n",
    "\n",
    "for i in range(len(label_folder)):\n",
    "    labelPath = data_path+r'\\\\'+label_folder[i]\n",
    "    \n",
    "    #listdir() returns a list containing the names of the entries in the directory given by path.\n",
    "    #isfile() is used to check whether the specified path is an existing regular file or not.\n",
    "    FileName = [f for f in listdir(labelPath) if isfile(join(labelPath, f))]\n",
    "    \n",
    "    for j in range(len(FileName)):\n",
    "        path = labelPath+r'\\\\'+FileName[j]\n",
    "        \n",
    "        #use cv2.imread read image.\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        \n",
    "        base_x_test.append(img)\n",
    "        base_y_test.append(label_folder[i])\n",
    "\n",
    "\n",
    "print(np.array(base_x_test).shape)\n",
    "print(np.array(base_y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d63c5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = model2.predict(np.array(base_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5961487a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y2 = np.zeros(y_final.shape[0])\n",
    "\n",
    "for i in range(y_final.shape[0]):\n",
    "    for j in range(y_final.shape[1]):\n",
    "        if y_final[i, j] >= max(y_final[i, ]):\n",
    "            output_y2[i] = j\n",
    "\n",
    "output_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4018afb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_y3 = np.zeros(to_categorical(base_y_test).shape[0])\n",
    "\n",
    "for i in range(to_categorical(base_y_test).shape[0]):\n",
    "    for j in range(to_categorical(base_y_test).shape[1]):\n",
    "        if to_categorical(base_y_test)[i, j] >= max(to_categorical(base_y_test)[i, ]):\n",
    "            output_y3[i] = j\n",
    "\n",
    "output_y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f5b3e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7889"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(output_y2 == output_y3)/to_categorical(base_y_test).shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
